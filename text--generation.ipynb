{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "m5ohZvWkjZ83",
    "outputId": "7fda173c-18d8-4c42-cc8b-523700e0d1d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importing dependencies\n",
    "import numpy\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jp24JCTORA_w"
   },
   "outputs": [],
   "source": [
    "#loading data \n",
    "# loading data and opening our input data in the form of a txt file\n",
    "#project Gutenberg/berg is where the data can be found \n",
    "file = open(\"Frankenstein.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upgOvkkGRamZ"
   },
   "outputs": [],
   "source": [
    "#tookenisation\n",
    "#standardisation \n",
    "#what is tokenization? Tokenization is the process of breaking a stream if text up into words phrases symbols or into \n",
    "# a meaningful elements.\n",
    "def tokenize_words(input):\n",
    "  # lowercase everything to a standardize it\n",
    "  input = input.lower()\n",
    "  # instantiating the tokenizer\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  # tokenizing the text into tokens\n",
    "  tokens = tokenizer.tokenize(input)\n",
    "  # filtering the stopwords using lambda\n",
    "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "  return \"\".join(filtered)\n",
    "\n",
    "# preprocess the input data, make tokens \n",
    "processed_inputs = tokenize_words(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udm_G7VsTh_K"
   },
   "outputs": [],
   "source": [
    "# chars to numbers \n",
    "# convert characters in our input to numbers\n",
    "# we'll sort the list of the set of all characters that appear in our i/p text and then use the enumerate fn\n",
    "# to get numbers that represent the characters \n",
    "# we'll then create a dictionary that stores the keys and values, or the characters and the numbers that represent them\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c,i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "zDuRJpxHXL5n",
    "outputId": "8be30448-f3f7-436f-c545-9695544506e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 233296\n",
      "Total vocab: 42\n"
     ]
    }
   ],
   "source": [
    "# Check if words to chars or chars  to num(?!) has worked?\n",
    "# just so wem get an idea of whether our process of convrting words to characters has worked,\n",
    "# we print the length of our variables\n",
    "input_len = len (processed_inputs)\n",
    "vocab_len = len (chars)\n",
    "print(\"Total number of characters:\", input_len)\n",
    "print(\"Total vocab:\", vocab_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHQrPs6nYY13"
   },
   "outputs": [],
   "source": [
    "#seq length\n",
    "# We're defining how long we want an individual sequence here\n",
    "# an individual sequence is a complete mapping of input characters as integers\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q-v4BHaOYnYT",
    "outputId": "c1672f21-b2e9-42a3-8e61-8e2bc5e7e04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 233196\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence \n",
    "# here we're going through the entire list of i/ps and converting the chars to numbers with a for loop\n",
    "# this will create a bunch of sequences where each sequence starts with the next character in the i/p data \n",
    "# begnning with the first character\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "  # define i/p and o/p sequences\n",
    "  # i/p is the current character plus the desired sequence length\n",
    "  in_seq = processed_inputs[i:i + seq_length]\n",
    "  # out sequence is the initial character plus total sequence length \n",
    "  out_seq = processed_inputs[i + seq_length]\n",
    "  # converting the list of characters to integers based on previous values and appending the values to our lists\n",
    "  x_data.append([char_to_num[char] for char in in_seq])\n",
    "  y_data.append(char_to_num[out_seq])\n",
    "\n",
    "# check to see how many total input sequence we have\n",
    "n_patterns = len(x_data)\n",
    "print(\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slUFYDl4aPer"
   },
   "outputs": [],
   "source": [
    "#convert input sequence to np array that our network can use \n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6fXOcWAa1cQ"
   },
   "outputs": [],
   "source": [
    "#one hot-encoding our label data\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clYICGwnbDpz"
   },
   "outputs": [],
   "source": [
    "#creating the model\n",
    "# creating a sequential model\n",
    "# dropout is used to prevent overfitting\n",
    "model= Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x40czfUrcdMM"
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGVOUkJFc-QZ"
   },
   "outputs": [],
   "source": [
    "#saving weights\n",
    "filepath = 'model_weights_saved.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose= 1, save_best_only=True, mode='min')\n",
    "desired_callbacks = (checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "ultH4IFSdqPM",
    "outputId": "978aa567-15d4-4858-d06f-a739a862b3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "911/911 [==============================] - ETA: 0s - loss: 2.9374\n",
      "Epoch 00001: loss improved from inf to 2.93740, saving model to model_weights_saved.hdf5\n",
      "911/911 [==============================] - 3321s 4s/step - loss: 2.9374\n",
      "Epoch 2/4\n",
      "911/911 [==============================] - ETA: 0s - loss: 2.9165\n",
      "Epoch 00002: loss improved from 2.93740 to 2.91652, saving model to model_weights_saved.hdf5\n",
      "911/911 [==============================] - 3347s 4s/step - loss: 2.9165\n",
      "Epoch 3/4\n",
      "911/911 [==============================] - ETA: 0s - loss: 2.9132\n",
      "Epoch 00003: loss improved from 2.91652 to 2.91320, saving model to model_weights_saved.hdf5\n",
      "911/911 [==============================] - 3359s 4s/step - loss: 2.9132\n",
      "Epoch 4/4\n",
      "911/911 [==============================] - ETA: 0s - loss: 2.8851\n",
      "Epoch 00004: loss improved from 2.91320 to 2.88515, saving model to model_weights_saved.hdf5\n",
      "911/911 [==============================] - 3392s 4s/step - loss: 2.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f62cb4e05c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model and let it train \n",
    "model.fit(X,y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxVZpdER2lNR"
   },
   "outputs": [],
   "source": [
    "# recompile model with the saved weights\n",
    "filename = 'model_weights_saved.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eeR3-7ZVSz5"
   },
   "outputs": [],
   "source": [
    "# output of the model back into characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "H-nhpvIKVqSf",
    "outputId": "477f0f96-2e25-4058-e3df-fc0e2fbde728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: \n",
      "\" confidencesinceritylistenedfathersilenceremainedtimeincapableofferingreplyrevolvedrapidlymindmultitu \"\n"
     ]
    }
   ],
   "source": [
    "# random seed to help generate \n",
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random seed: \")\n",
    "print(\"\\\"\" , ''.join([num_to_char[value] for value in  pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MuSKP2B5XD5x",
    "outputId": "288978d7-da25-4d01-f6e9-f20591a5b8cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eneeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
     ]
    }
   ],
   "source": [
    "# generate the text\n",
    "for i in range(1000):\n",
    "  x = numpy.reshape(pattern, (1,len(pattern), 1))\n",
    "  x = x/float(vocab_len)\n",
    "  prediction = model.predict(x, verbose=0)\n",
    "  index = numpy.argmax(prediction)\n",
    "  result = num_to_char[index]\n",
    "  seq_in = [num_to_char[value] for value in pattern]\n",
    "  sys.stdout.write(result)\n",
    "  pattern.append(index)\n",
    "  pattern = pattern[ 1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCJ1RSCrYhzd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPcA4PZg3sPbhcoWlRdyXZt",
   "include_colab_link": true,
   "name": "txt generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
